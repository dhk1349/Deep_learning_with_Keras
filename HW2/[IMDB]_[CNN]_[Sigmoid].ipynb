{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>IMDB dateset</h2>\n",
    "\n",
    "IMDB는 (영화 리뷰, 리뷰의 긍정부정 값)을 한 쌍의 데이터 값으로, 50,000개의 샘플을 모아 놓은 데이터 셋이다. 이 중 25,000개의 댓글 셈플은 트레이닝 샘플이며, 나머지 25,000개의 댓글 샘플은 테스팅 샘플이다.<br>\n",
    "다시말해, 해당 데이터 셋에는 50000개의 영화 리뷰를 가지고 있으며, 모든 리뷰들은 결과 값(부정 혹은 긍적) 값을 결과 값으로 가지고 있다. \n",
    "해당 데이터 셋의 결과 값이 이진 데이터라는 특성 때문에 해당 데이터 셋을 사용하는 신경망 모델의 목적은 주로 binary classification을 목적으로 한다.\n",
    "\n",
    "해당 파일에서는 편의를 위해 데이터를 로드할 때, 가장 빈번하게 사용되는 20,000개의 단어들만 포함하여 로드하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 내부에서 training을 위한 데이터와 이를 각 epoch에서 검증하기 위한 데이터를 분류\n",
    "하기 위해 25,000개의 데이터를 분할하였다.<br>\n",
    "25,000개이 샘플 중 20,000개는 트레이닝을 위한 샘플, 나머지 5,000개는 트레이닝 후 정확도 평가를 위한 validation 샘플로 두었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=x_train[20000:]\n",
    "y_val=y_train[20000:]\n",
    "\n",
    "x_train=x_train[:20000]\n",
    "y_train=y_train[:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>pad_sequence() function</h4>\n",
    "pad_sequence()라는 함수는 케라스에 내장되어 있는 함수로, 데이터 전처리를 하는 것이 그 용도이다. </br>\n",
    "해당 함수를 사용하면, 샘플 간의 길이를 균등하게 맞출 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "x_train=sequence.pad_sequences(x_train, maxlen=200) #길이 200으로 맞춤\n",
    "x_val=sequence.pad_sequences(x_val, maxlen=200)\n",
    "x_test=sequence.pad_sequences(x_test, maxlen=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>모델 구성</h2>\n",
    "Sequential() 함수로 모델을 초기화 한다.\n",
    "\n",
    "<h4>Embedding()층을 추가한다</h4>\n",
    "Embedding()은 one-hot-encoding보다 훨씬 적은 공간을 사용한다. 또한 해당 층을 추가하면 단어 간의 연관성을 고려한 벡터가 만들어지기 때문에 훨씬 유의미한 훈련이 가능하다.\n",
    "\n",
    "<h4>Dropout</h4>\n",
    "Dropout은 훈련 중에 과대적합을 방지하기 위해서 추가된 층이다.\n",
    "\n",
    "<h4>Conv1D</h4>\n",
    "Convolutional Neural Network(CNN)은 주로 2차원으로 사용할 때 이미지 훈련에서 빈번하게 사용된다. 하지만 이 외의 분류 모델에서도 사용이 용이하다.<br> \n",
    "CNN은 지정한 갯수만큼의 fileter(합성곱 윈도우)를 가지고 데이터가 가지고 있는 패턴을 찾아낸다. 이 때, 필터를 많이 가지고 있을수록, 더 다양한 패턴을 인식하게 된다. 그러나 연산량은 많아진다. \n",
    "\n",
    "<h4>GlobalMaxPooling</h4>\n",
    "Pooling은 벡터에서 특징적인 값만 추출하는 과정이다. 특정한 벡터만 추출해서 사용하게 되면 과대적합 문제를 해결하는데에 도움을 줄 수 있다.<br>GlobalMaxPooling의 경우에는 여러 개의 벡터 정보 중에서 가장 큰 정보만 추출해오는 pooling 방법인다.  \n",
    "\n",
    "\n",
    "<h4>출력층: Sigmoid 함수</h4>\n",
    "해당 모델의 목적은 입력되는 리뷰의 긍정 부정을 판별하는 것이다. Binary classification에 적합한 Sigmoid 함수를 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(20000, 128, input_length=200))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(256, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 198, 256)          98560     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,658,817\n",
      "Trainable params: 2,658,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dhk13\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\dhk13\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "20000/20000 [==============================] - 69s 3ms/step - loss: 0.4959 - acc: 0.7537 - val_loss: 0.3251 - val_acc: 0.8654\n",
      "Epoch 2/25\n",
      "20000/20000 [==============================] - 64s 3ms/step - loss: 0.2722 - acc: 0.8901 - val_loss: 0.2826 - val_acc: 0.8810\n",
      "Epoch 3/25\n",
      "20000/20000 [==============================] - 64s 3ms/step - loss: 0.1681 - acc: 0.9368 - val_loss: 0.2792 - val_acc: 0.8854\n",
      "Epoch 4/25\n",
      "20000/20000 [==============================] - 62s 3ms/step - loss: 0.0894 - acc: 0.9714 - val_loss: 0.3079 - val_acc: 0.8846\n",
      "Epoch 5/25\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 0.0419 - acc: 0.9884 - val_loss: 0.3703 - val_acc: 0.8802\n",
      "Epoch 6/25\n",
      "20000/20000 [==============================] - 62s 3ms/step - loss: 0.0189 - acc: 0.9960 - val_loss: 0.4202 - val_acc: 0.8768\n",
      "Epoch 7/25\n",
      "20000/20000 [==============================] - 65s 3ms/step - loss: 0.0106 - acc: 0.9982 - val_loss: 0.4692 - val_acc: 0.8726\n",
      "Epoch 8/25\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.5071 - val_acc: 0.8672\n",
      "Epoch 9/25\n",
      "20000/20000 [==============================] - 64s 3ms/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.5291 - val_acc: 0.8682\n",
      "Epoch 10/25\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 0.5611 - val_acc: 0.8668\n",
      "Epoch 11/25\n",
      "20000/20000 [==============================] - 64s 3ms/step - loss: 0.0015 - acc: 0.9999 - val_loss: 0.5831 - val_acc: 0.8676\n",
      "Epoch 12/25\n",
      "20000/20000 [==============================] - 62s 3ms/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.6077 - val_acc: 0.8704\n",
      "Epoch 13/25\n",
      "20000/20000 [==============================] - 64s 3ms/step - loss: 9.1218e-04 - acc: 1.0000 - val_loss: 0.6359 - val_acc: 0.8670\n",
      "Epoch 14/25\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 8.2247e-04 - acc: 0.9999 - val_loss: 0.6596 - val_acc: 0.8614\n",
      "Epoch 15/25\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.6833 - val_acc: 0.8634\n",
      "Epoch 16/25\n",
      "20000/20000 [==============================] - 85s 4ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.6989 - val_acc: 0.8652\n",
      "Epoch 17/25\n",
      "20000/20000 [==============================] - 100s 5ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.7547 - val_acc: 0.8592\n",
      "Epoch 18/25\n",
      "20000/20000 [==============================] - 102s 5ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.7502 - val_acc: 0.8626\n",
      "Epoch 19/25\n",
      "20000/20000 [==============================] - 103s 5ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.7845 - val_acc: 0.8618\n",
      "Epoch 20/25\n",
      "20000/20000 [==============================] - 87s 4ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.8334 - val_acc: 0.8602\n",
      "Epoch 21/25\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.8399 - val_acc: 0.8602\n",
      "Epoch 22/25\n",
      "20000/20000 [==============================] - 64s 3ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.8671 - val_acc: 0.8586\n",
      "Epoch 23/25\n",
      "20000/20000 [==============================] - 61s 3ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.8750 - val_acc: 0.8576\n",
      "Epoch 24/25\n",
      "20000/20000 [==============================] - 65s 3ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.9101 - val_acc: 0.8548\n",
      "Epoch 25/25\n",
      "20000/20000 [==============================] - 64s 3ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.9640 - val_acc: 0.8498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15220eb3f60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=25, batch_size=64, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 21s 833us/step\n",
      "====Test Loss====\n",
      "1.0296555969542265\n",
      "====Test Accuracy\n",
      "0.84088\n"
     ]
    }
   ],
   "source": [
    "result=model.evaluate(x_test, y_test)\n",
    "print(\"====Test Loss====\")\n",
    "print(result[0])\n",
    "print(\"====Test Accuracy\")\n",
    "print(result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
